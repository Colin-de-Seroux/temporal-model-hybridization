{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47dacdf",
   "metadata": {},
   "source": [
    "# GconvGRU\n",
    "\n",
    "Chaque modelName va correspondre √† un graph √† un certain temps\n",
    "\n",
    "DynamicGraphTemporalSignal:  graph qui  peut √©voluer (+ ou - de noeuds / edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088d5774",
   "metadata": {},
   "source": [
    "## C√©ation du dataset depuis le fichier csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe201d",
   "metadata": {},
   "source": [
    "edge weight = abs(dst_execution_time - src_execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ffdab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal\n",
    "\n",
    "class CustomDynamicGraphTemporalSignal(DynamicGraphTemporalSignal):\n",
    "    def __init__(self, edge_indices, edge_weights, features, targets):\n",
    "        super().__init__(edge_indices=edge_indices,edge_weights=edge_weights ,features=features, targets=targets)\n",
    "        self.edge_weights = edge_weights\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.features)):\n",
    "            yield type('Snapshot', (), {\n",
    "                \"x\": self.features[i],\n",
    "                \"y\": self.targets[i],\n",
    "                \"edge_index\": self.edge_indices[i],\n",
    "                \"edge_weight\": self.edge_weights[i]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88c0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal\n",
    "\n",
    "def encode_action_type(action_type):\n",
    "    return {\n",
    "        'timer': [1, 0, 0],\n",
    "        'pub': [0, 1, 0],\n",
    "        'sub': [0, 0, 1]\n",
    "    }.get(action_type, [0, 0, 0])\n",
    "\n",
    "def create_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.sort_values(by=[\"ModelName\", \"NodeName\", \"ActionOrder\"])\n",
    "\n",
    "    unique_topics = df[\"Topic\"].dropna().unique()\n",
    "    topic_to_id = {topic: i for i, topic in enumerate(unique_topics)}\n",
    "\n",
    "    snapshots = []\n",
    "\n",
    "    for model_name, group in df.groupby(\"ModelName\"):\n",
    "        node_ids = []\n",
    "        features = []\n",
    "        targets = []\n",
    "\n",
    "        node_index_map = {} \n",
    "        node_exec_time = {}\n",
    "        idx = 0\n",
    "\n",
    "        # Construction des noeuds\n",
    "        for _, row in group.iterrows():\n",
    "            node_id = f'{row[\"NodeName\"]}-{row[\"ActionType\"]}'\n",
    "            if node_id not in node_index_map:\n",
    "                node_index_map[node_id] = idx\n",
    "                idx += 1\n",
    "\n",
    "                one_hot = encode_action_type(row[\"ActionType\"])\n",
    "                topic_id = topic_to_id.get(row[\"Topic\"], -1)\n",
    "                period = row[\"Value\"] / 1000.0 if row[\"ActionType\"] == \"timer\" else row[\"Value\"]\n",
    "                feature_vector = one_hot + [topic_id, period, row[\"ActionOrder\"]]\n",
    "                features.append(feature_vector)\n",
    "                exec_time = row[\"ExecutionTime\"]\n",
    "                targets.append(exec_time)\n",
    "                node_exec_time[node_id] = exec_time\n",
    "                node_ids.append({\n",
    "                    \"id\": node_id,\n",
    "                    \"NodeName\": row[\"NodeName\"],\n",
    "                    \"ActionType\": row[\"ActionType\"],\n",
    "                    \"Topic\": row[\"Topic\"]\n",
    "                })\n",
    "\n",
    "        num_nodes = len(node_index_map)\n",
    "        x = np.array(features)\n",
    "        y = np.array(targets)\n",
    "\n",
    "        edge_list = []\n",
    "        edge_weights = []\n",
    "\n",
    "        # Ar√™tes : timer -> pub (m√™me NodeName)\n",
    "        timers = group[group[\"ActionType\"] == \"timer\"]\n",
    "        publishers = group[group[\"ActionType\"] == \"pub\"]\n",
    "        subscribers = group[group[\"ActionType\"] == \"sub\"]\n",
    "\n",
    "        for _, timer in timers.iterrows():\n",
    "            for _, pub in publishers.iterrows():\n",
    "                if timer[\"NodeName\"] == pub[\"NodeName\"]:\n",
    "                    src = f'{timer[\"NodeName\"]}-timer'\n",
    "                    dst = f'{pub[\"NodeName\"]}-pub'\n",
    "                    if src in node_index_map and dst in node_index_map:\n",
    "                        edge_list.append((node_index_map[src], node_index_map[dst]))\n",
    "                        weight = abs(node_exec_time[dst] - node_exec_time[src])\n",
    "                        edge_weights.append(weight)\n",
    "\n",
    "        # Ar√™tes : pub -> sub (m√™me topic)\n",
    "        for _, pub in publishers.iterrows():\n",
    "            for _, sub in subscribers.iterrows():\n",
    "                if pub[\"Topic\"] == sub[\"Topic\"]:\n",
    "                    src = f'{pub[\"NodeName\"]}-pub'\n",
    "                    dst = f'{sub[\"NodeName\"]}-sub'\n",
    "                    if src in node_index_map and dst in node_index_map:\n",
    "                        edge_list.append((node_index_map[src], node_index_map[dst]))\n",
    "                        weight = abs(node_exec_time[dst] - node_exec_time[src])\n",
    "                        edge_weights.append(weight)\n",
    "\n",
    "        if edge_list:\n",
    "\n",
    "            edge_index = np.array(edge_list).T \n",
    "            edge_weight = np.array(edge_weights, dtype=np.float32)\n",
    "   \n",
    "        else:\n",
    "            edge_index = np.empty((2, 0), dtype=np.int64)\n",
    "            edge_weight = np.empty((0,), dtype=np.float32)\n",
    "       \n",
    "\n",
    "        snapshots.append((x, edge_index, edge_weight, y))\n",
    "\n",
    "    features = [snap[0] for snap in snapshots]\n",
    "    edge_indices = [snap[1] for snap in snapshots]\n",
    "    edge_weights = [snap[2] for snap in snapshots]\n",
    "    # print(\"****************************************\")\n",
    "    # print(\"edge_weights : \", edge_weights)\n",
    "    targets = [snap[3] for snap in snapshots]\n",
    "    for i, (ei, ew, f, t) in enumerate(zip(edge_indices, edge_weights, features, targets)):\n",
    "        # print(f\"Snapshot {i}: edge_index shape = {ei.shape}, edge_weight shape = {ew.shape if ew is not None else None}\")\n",
    "        if ew is not None and ei.shape[1] != ew.shape[0]:\n",
    "            print(f\"  Mismatch in snapshot {i} between edge_index and edge_weight lengths!\")\n",
    "\n",
    "    return CustomDynamicGraphTemporalSignal(\n",
    "        edge_indices=edge_indices,\n",
    "        edge_weights=edge_weights,\n",
    "        features=features,\n",
    "        targets=targets\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e35fa7",
   "metadata": {},
   "source": [
    "## Debug dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a339a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def debug_dataset(dataset):\n",
    "    for t, snapshot in enumerate(dataset):\n",
    "        print(f\"\\nüïí Snapshot {t}\")\n",
    "        print(\"Edge Index:\")\n",
    "        print(snapshot.edge_index)\n",
    "\n",
    "        print(\"Node Features:\")\n",
    "        print(snapshot.x)\n",
    "        print(\"Targets:\")\n",
    "        print(snapshot.y)\n",
    "\n",
    "        # G = nx.DiGraph()\n",
    "        # num_nodes = snapshot.x.shape[0]\n",
    "        # for i in range(num_nodes):\n",
    "        #     G.add_node(i, feature=snapshot.x[i], target=snapshot.y[i])\n",
    "\n",
    "        # for src, dst in snapshot.edge_index.T:\n",
    "        #     G.add_edge(src, dst)\n",
    "\n",
    "        # pos = nx.spring_layout(G, seed=42)\n",
    "        # labels = {i: f\"{i}\\n{snapshot.y[i]:.3f}\" for i in range(num_nodes)}\n",
    "        # nx.draw(G, pos, with_labels=True, labels=labels, node_color='skyblue', edge_color='gray')\n",
    "        # plt.title(f\"Graphe au snapshot {t}\")\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0817a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(\"../dataset/dataset.csv\")\n",
    "debug_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec775fe5",
   "metadata": {},
   "source": [
    "## Pr√©dictions sans visualisation graphique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d385bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.nn import L1Loss\n",
    "mae_fn = L1Loss()\n",
    "\n",
    "dataset = create_dataset(\"../dataset/dataset.csv\")\n",
    "\n",
    "all_features = np.vstack([snapshot.x for snapshot in dataset])\n",
    "all_targets = np.concatenate([snapshot.y for snapshot in dataset]).reshape(-1, 1)\n",
    "\n",
    "feature_scaler = MinMaxScaler()\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "feature_scaler.fit(all_features)\n",
    "target_scaler.fit(all_targets)\n",
    "\n",
    "# Mod√®le avec GConvGRU\n",
    "class GConvGRUModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.recurrent = GConvGRU(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            K=2  \n",
    "        )\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, 1),\n",
    "            torch.nn.Softplus()  \n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, h):\n",
    "        h = self.recurrent(x, edge_index, edge_weight, h)\n",
    "        out = self.linear(F.relu(h))\n",
    "        return out, h\n",
    "\n",
    "# Initialisation\n",
    "model = GConvGRUModel(in_channels=6, out_channels=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(all_targets, bins=100)\n",
    "plt.title(\"Distribution des temps d'ex√©cution\")\n",
    "plt.xlabel(\"Execution Time (s)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Entra√Ænement\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    loss_total = 0\n",
    "    mae_total = 0\n",
    "    h = None\n",
    "    for snapshot in dataset:\n",
    "      \n",
    "        x_norm = feature_scaler.transform(snapshot.x)\n",
    "        y_norm = target_scaler.transform(snapshot.y.reshape(-1, 1))\n",
    "\n",
    "        x = torch.FloatTensor(x_norm)\n",
    "        y = torch.FloatTensor(y_norm)\n",
    "\n",
    "        edge_index = torch.LongTensor(snapshot.edge_index.T if snapshot.edge_index.shape[0] != 2 else snapshot.edge_index)\n",
    "        edge_weight = torch.FloatTensor(snapshot.edge_weight) if snapshot.edge_weight is not None else torch.ones(edge_index.shape[1])\n",
    "\n",
    "\n",
    "        if h is None or h.size(0) != x.size(0):\n",
    "            h = torch.zeros(x.size(0), model.recurrent.out_channels)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out, h = model(x, edge_index, edge_weight, h)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if h is not None:\n",
    "            h = h.detach()\n",
    "        loss_total += loss.item()\n",
    "        mae_total += mae_fn(out, y).item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss_total:.4f}, MAE: {mae_total:.4f}\")\n",
    "\n",
    "# Pr√©diction\n",
    "print(\"\\n Predictions :\")\n",
    "model.eval()\n",
    "h = None\n",
    "#for snapshot in dataset:\n",
    "for t, snapshot in enumerate(dataset):\n",
    "    x_norm = feature_scaler.transform(snapshot.x)\n",
    "    x = torch.FloatTensor(x_norm)\n",
    "    # y = torch.FloatTensor(snapshot.y)\n",
    "    y_norm = target_scaler.transform(snapshot.y.reshape(-1, 1))\n",
    "    y = torch.FloatTensor(y_norm)\n",
    "\n",
    " \n",
    "    edge_index = torch.LongTensor(snapshot.edge_index.T if snapshot.edge_index.shape[0] != 2 else snapshot.edge_index)\n",
    "    edge_weight = torch.FloatTensor(snapshot.edge_weight) if snapshot.edge_weight is not None else torch.ones(edge_index.shape[1])\n",
    "\n",
    "\n",
    "    if h is None or h.size(0) != x.size(0):\n",
    "        h = torch.zeros(x.size(0), model.recurrent.out_channels)\n",
    "\n",
    "\n",
    "    out, h = model(x, edge_index, edge_weight, h)\n",
    "    out_norm = out.view(-1).detach().numpy().reshape(-1, 1)\n",
    "    out_original = target_scaler.inverse_transform(out_norm).flatten()\n",
    "    y_norm = y.view(-1).detach().numpy().reshape(-1, 1)\n",
    "    real = target_scaler.inverse_transform(y_norm).flatten()\n",
    "    print(f\"Pr√©diction (d√©normalis√©e) : {out_original}\")\n",
    "    print(f\"R√©el                   : {real}\")\n",
    "    for i, (p, r) in enumerate(zip(out_original, real)):\n",
    "        print(f\"Noeud {i} -> Pr√©diction: {p:.3f}, R√©el: {r:.3f}\")\n",
    "        print()\n",
    "    # plt.figure(figsize=(6,4))\n",
    "    # nodes = np.arange(len(out_original))\n",
    "    # plt.plot(nodes, real, 'o-', label='Valeurs r√©elles')\n",
    "    # plt.plot(nodes, out_original, 'x--', label='Pr√©dictions')\n",
    "    # plt.title(f\"Comparaison pr√©dictions vs valeurs r√©elles (snapshot {t})\")\n",
    "    # plt.xlabel(\"Noeud\")\n",
    "    # plt.ylabel(\"Valeur\")\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044887c",
   "metadata": {},
   "source": [
    "## avec matplotlib (visualisation graphique donn√©es r√©elles VS pr√©dictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6126a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torch.nn import L1Loss\n",
    "mae_fn = L1Loss()\n",
    "\n",
    "# Cr√©ation du dataset dynamique\n",
    "edge_indices = [\n",
    "    np.array([[0, 1], [1, 2]]).T,\n",
    "    np.array([[0, 2], [2, 1]]).T,\n",
    "    np.array([[1, 0], [2, 0]]).T,\n",
    "]\n",
    "\n",
    "edge_weights = [\n",
    "    np.array([1.0, 2.0]),\n",
    "    np.array([0.5, 1.5]),\n",
    "    np.array([2.0, 1.0])\n",
    "]\n",
    "\n",
    "features = [\n",
    "    np.array([[1, 0], [0, 1], [1, 1]]),\n",
    "    np.array([[2, 0], [1, 1], [0, 1]]),\n",
    "    np.array([[1, 1], [2, 1], [1, 0]]),\n",
    "]\n",
    "\n",
    "targets = [\n",
    "    np.array([0.1, 0.2, 0.3]),\n",
    "    np.array([0.2, 0.1, 0.4]),\n",
    "    np.array([0.3, 0.2, 0.5]),\n",
    "]\n",
    "\n",
    "dataset = DynamicGraphTemporalSignal(\n",
    "    edge_indices=edge_indices,\n",
    "    edge_weights=edge_weights,\n",
    "    features=features,\n",
    "    targets=targets,\n",
    ")\n",
    "\n",
    "# Mod√®le avec GConvGRU\n",
    "class GConvGRUModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.recurrent = GConvGRU(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            K=2 \n",
    "        )\n",
    "        self.linear = torch.nn.Linear(out_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, h):\n",
    "        h = self.recurrent(x, edge_index, edge_weight, h)\n",
    "        out = self.linear(F.relu(h))\n",
    "        return out, h\n",
    "\n",
    "# Initialisation\n",
    "model = GConvGRUModel(in_channels=2, out_channels=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Entra√Ænement\n",
    "model.train()\n",
    "for epoch in range(300):\n",
    "    loss_total = 0\n",
    "    mae_total = 0\n",
    "    h = None\n",
    "    for snapshot in dataset:\n",
    "        x = torch.FloatTensor(snapshot.x)\n",
    "        y = torch.FloatTensor(snapshot.y).view(-1, 1)\n",
    "        edge_index = torch.LongTensor(snapshot.edge_index.T)\n",
    "        edge_weight = (\n",
    "            torch.FloatTensor(snapshot.edge_weight)\n",
    "            if snapshot.edge_weight is not None\n",
    "            else torch.ones(edge_index.shape[1])\n",
    "        )\n",
    "\n",
    "        if h is None:\n",
    "            h = torch.zeros(x.size(0), 4)  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out, h = model(x, edge_index, edge_weight, h)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward(retain_graph=True )\n",
    "        optimizer.step()\n",
    "        if h is not None:\n",
    "            h = h.detach()\n",
    "        loss_total += loss.item()\n",
    "        mae_total += mae_fn(out, y).item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss_total:.4f}, MAE: {mae_total:.4f}\")\n",
    "\n",
    "# Pr√©diction\n",
    "print(\"\\nüìà Predictions :\")\n",
    "model.eval()\n",
    "h = None\n",
    "for t, snapshot in enumerate(dataset):\n",
    "    x = torch.FloatTensor(snapshot.x)\n",
    "    y = torch.FloatTensor(snapshot.y)\n",
    "    edge_index = torch.LongTensor(snapshot.edge_index)\n",
    "    edge_weight = (\n",
    "        torch.FloatTensor(snapshot.edge_weight)\n",
    "        if snapshot.edge_weight is not None\n",
    "        else torch.ones(edge_index.shape[1])\n",
    "    )\n",
    "    out, h = model(x, edge_index, edge_weight, h)\n",
    "    pred = out.view(-1).detach().numpy()\n",
    "    real = y.numpy()\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    nodes = np.arange(len(pred))\n",
    "    plt.plot(nodes, real, 'o-', label='Valeurs r√©elles')\n",
    "    plt.plot(nodes, pred, 'x--', label='Pr√©dictions')\n",
    "    plt.title(f\"Comparaison pr√©dictions vs valeurs r√©elles (snapshot {t})\")\n",
    "    plt.xlabel(\"Noeud\")\n",
    "    plt.ylabel(\"Valeur\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
